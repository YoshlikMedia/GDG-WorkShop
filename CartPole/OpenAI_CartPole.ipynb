{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAI-CartPole.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbfBT4x0r03r"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "env = gym.make(\"CartPole-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "metadata": {
        "id": "o8VjOPC3r3iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "id": "y_g96z-lr6qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# returns an initial observation\n",
        "env.reset()\n",
        "\n",
        "for i in range(20):\n",
        "\n",
        "  # env.action_space.sample() produces either 0 (left) or 1 (right).\n",
        "  observation, reward, done, info = env.step(env.action_space.sample())\n",
        "\n",
        "  print(\"step\", i, observation, reward, done, info)\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "yPdbHXz0r8sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies needed for recording videos\n",
        "!apt-get install -y xvfb x11-utils\n",
        "!pip install pyvirtualdisplay==0.2.*"
      ],
      "metadata": {
        "id": "dmAweRoSr_jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=False, size=(1400, 900))\n",
        "_ = display.start()"
      ],
      "metadata": {
        "id": "NHEVLV1bsCNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "before_training = \"before_training.mp4\"\n",
        "\n",
        "video = VideoRecorder(env, before_training)\n",
        "# returns an initial observation\n",
        "env.reset()\n",
        "for i in range(200):\n",
        "  env.render()\n",
        "  video.capture_frame()\n",
        "  # env.action_space.sample() produces either 0 (left) or 1 (right).\n",
        "  observation, reward, done, info = env.step(env.action_space.sample())\n",
        "  # Not printing this time\n",
        "  #print(\"step\", i, observation, reward, done, info)\n",
        "\n",
        "video.close()\n",
        "env.close()"
      ],
      "metadata": {
        "id": "l_cBhqFRsEqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import b64encode\n",
        "def render_mp4(videopath: str) -> str:\n",
        "  \"\"\"\n",
        "  Gets a string containing a b4-encoded version of the MP4 video\n",
        "  at the specified path.\n",
        "  \"\"\"\n",
        "  mp4 = open(videopath, 'rb').read()\n",
        "  base64_encoded_mp4 = b64encode(mp4).decode()\n",
        "  return f'<video width=400 controls><source src=\"data:video/mp4;' \\\n",
        "         f'base64,{base64_encoded_mp4}\" type=\"video/mp4\"></video>'"
      ],
      "metadata": {
        "id": "LpbIgfWvsHYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "html = render_mp4(before_training)\n",
        "HTML(html)"
      ],
      "metadata": {
        "id": "Iej8e-l6sKRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'ray[rllib]'==1.6"
      ],
      "metadata": {
        "id": "mbwMCEBysNI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from ray.rllib.agents.ppo import PPOTrainer\n",
        "config = {\n",
        "    \"env\": \"CartPole-v0\",\n",
        "    # Change the following line to `“framework”: “tf”` to use tensorflow\n",
        "    \"framework\": \"torch\",\n",
        "    \"model\": {\n",
        "      \"fcnet_hiddens\": [32],\n",
        "      \"fcnet_activation\": \"linear\",\n",
        "    },\n",
        "}\n",
        "stop = {\"episode_reward_mean\": 195}\n",
        "ray.shutdown()\n",
        "ray.init(\n",
        "  num_cpus=3,\n",
        "  include_dashboard=False,\n",
        "  ignore_reinit_error=True,\n",
        "  log_to_driver=False,\n",
        ")\n",
        "# execute training \n",
        "analysis = ray.tune.run(\n",
        "  \"PPO\",\n",
        "  config=config,\n",
        "  stop=stop,\n",
        "  checkpoint_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "gmxt8qyksR4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restore a trainer from the last checkpoint\n",
        "trial = analysis.get_best_logdir(\"episode_reward_mean\", \"max\")\n",
        "checkpoint = analysis.get_best_checkpoint(\n",
        "  trial,\n",
        "  \"training_iteration\",\n",
        "  \"max\",\n",
        ")\n",
        "trainer = PPOTrainer(config=config)\n",
        "trainer.restore(checkpoint)"
      ],
      "metadata": {
        "id": "C7FFAi5DsVi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after_training = \"after_training.mp4\"\n",
        "after_video = VideoRecorder(env, after_training)\n",
        "observation = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "  env.render()\n",
        "  after_video.capture_frame()\n",
        "  action = trainer.compute_action(observation)\n",
        "  observation, reward, done, info = env.step(action)\n",
        "after_video.close()\n",
        "env.close()\n",
        "# You should get a video similar to the one below. \n",
        "html = render_mp4(after_training)\n",
        "HTML(html)"
      ],
      "metadata": {
        "id": "MdU_iNv1scej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}